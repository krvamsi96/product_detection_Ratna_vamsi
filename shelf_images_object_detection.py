# -*- coding: utf-8 -*-
"""shelf images_object detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1khayncVBeqCKGFgQR31QfdmeuRLRO_B0
"""

# Commented out IPython magic to ensure Python compatibility.
# Defining Functions that are useful in  future to download , Upload and print files.
def imShow(path):
  import cv2
  import matplotlib.pyplot as plt
#   %matplotlib inline

  image = cv2.imread(path)
  height, width = image.shape[:2]
  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)

  fig = plt.gcf()
  fig.set_size_inches(18, 10)
  plt.axis("off")
  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))
  plt.show()

# use this to upload files
def upload():
  from google.colab import files
  uploaded = files.upload() 
  for name, data in uploaded.items():
    with open(name, 'wb') as f:
      f.write(data)
      print ('saved file', name)

# use this to download a file  
def download(path):
  from google.colab import files
  files.download(path)

"""**Downloading Dataset**"""

#this code sets the data up, the extracted file shelfimages can probably be shared as shelfimages1 ev

!git clone https://github.com/gulvarol/grocerydataset/ #cloning git repository of meta data and description
!wget https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz #downloads add on provided by the assignment
!tar --gunzip --extract --verbose --file=ShelfImages.tar.gz #extracts add ondata tar folder

"""**Data Preperation**"""

# Commented out IPython magic to ensure Python compatibility.
#changing working directory 
# %cd grocerydataset/

#reading the data from an annotation file to a dictionary with file names as key and the data of the objects in it as a dict (list ) attached to the key


#open a file into a file variable f 
f = open('annotation.txt') 

#Loads the entire content into a variable l ( A large string ). Uncomment print(l) to find more
l = f.read()
#print(l)

#The following command Splits the big text and writes each line into a fresh string. And compiles the strings into an array of strings uncomment to witness 
k = l.splitlines()
m = list(k)
#print(m)

#creating an empty dict 
Dictionarydata = dict()

#Iterating over list of strings. Each i refers to one image 
for i in m :
  #splits each string into various little strings whenever a space is encountered
  p = i.split()
  #the first string in that contains the name of image. So we create a dict with name of the image as key  and write the rest of the data to that key as values uncomment printbelow to find it out
  Dictionarydata[p[0]]= p[1:]
  #print(Dictionarydata)

# Commented out IPython magic to ensure Python compatibility.
#taking the list of files in test and train directories and storing them as a list of strings. 
#os.lisdir() Function lists all the available files in the current working directory into a list of strings. Uncomment print to understand the output
import os 
# %cd ..
# %cd 'ShelfImages/test'
testlist = os.listdir()
#print(testlist)
# %cd ..
# %cd train
trainlist = os.listdir()
#print(trainlist)
# %cd ..

#yolo usually asks for text files corresponding to each image
#In order to create names for text files this would be very handy 


#creating two empty lists
trainlistnamestextfiles = list() 
testlistnamestextfiles = list()

#iterating over the Previously obtained lists which contains the 
for i in trainlist :
  #the last three letters of image names are jpg when we remove them and name txt , we have the names of the corresponding text files uncomment print function in the end to find out how they unveil 
  trainlistnamestextfiles.append(str(i[:-3])+'txt')
for i in testlist :
  testlistnamestextfiles.append(str(i[:-3])+'txt')

#print(trainlistnamestextfiles)
#print(testlistnamestextfiles)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import cv2 
# %cd 
# %cd ..
# %cd /content/ShelfImages/train

#Now we are iterating over the trainlist and testlist Lists so that we can do data processing

for i in range(len(trainlist)) :

  #as we know that the dictionarydata contains the dict with images names as key and A long list of strings which are numbers as the value
  arrayofsinglefile = Dictionarydata[trainlist[i]] 
  #print(arrayofsinglefile, '\n')

  # The First string of the list is the number of detections obtained in a particular image 
  countofdetectionsinparticularimage = arrayofsinglefile[0]
  #print(countofdetectionsinparticularimage)
  #print('\n')

  #The rest of the list is x, y , width , height , class repeated count number of times. so Now we reshape the list and write each object in a row and 5 columns containing , 
  array = np.array(arrayofsinglefile[1:],dtype = float).reshape(int(countofdetectionsinparticularimage),5)
  
  #now we need classes in the first column according to the format YOLO accepts. and all other colums should be moved right. So we use np.roll() 
  #This pushes 4 all the colums to one step right and brings the lost column to the first

  array=np.roll(array, 1, axis=1)
  #print(array, '\n')

  #as I said that the inputs of each files to YOLO should be floats
  image = cv2.imread(trainlist[i])
  height,width= image.shape[0],image.shape[1]
  #print(height,width)
  #print('\n')
  #print(len(array))
  #print(array[:][:])
  for j in range(int(countofdetectionsinparticularimage)):
    for k in range(1,5):
      #print(k)
      if(k== 2):
        array[j][k]=int(array[j][k])/height
        #if array[j][k]>1:
          #print('error2')
          #print(array[j][k],height,width) # uncomment these if you find an error stating that , the values of weights either less than zero or greater than 1 
      elif(k == 4):
        array[j][k]=int(array[j][k])/height
        #if array[j][k]>1: 
          #print('error4')
          #print(array[j][k],height,width)
      elif(k== 3):
        array[j][k]=int(array[j][k])/width
        #if array[j][k]>1:
          #print('error3')
          #print(array[j][k],height,width)
      elif(k==1 ):
        array[j][k]=int(array[j][k])/width
        #if array[j][k]>1:
          #print('error1')
          #print(array[j][k],height,width)
  #print(array, '\n')



  # thus we obtained an array that is exactly same as how each file should look 
  #opening the file and writing the array in the text file
  
  with open('{}'.format(trainlistnamestextfiles[i]), 'w') as f:
    for x in range(int(countofdetectionsinparticularimage)):

      for y in range(5):
        if y == 0 :
          f.write(str(0) + ' ')
          #f.write(str(float(array[x][y])) + ' ') uncomment this for 11 objects training
        else:
          f.write(str(float(array[x][y])) + ' ')
      f.write('\n')

# Commented out IPython magic to ensure Python compatibility.
#the comments are same as the above cell, just the folder changes. 
import numpy as np
import cv2 
# %cd /content/ShelfImages/test

for i in range(len(testlist)) :
  arrayofsinglefile = Dictionarydata[testlist[i]]
  #print(arrayofsinglefile, '\n')
  countofdetectionsinparticularimage = arrayofsinglefile[0]
  #print(countofdetectionsinparticularimage)
  #print('\n')
  array = np.array(arrayofsinglefile[1:],dtype = float).reshape(int(countofdetectionsinparticularimage),5)
  # reshapethedata=array.reshape(int(countofdetectionsinparticularimage),5))
  #To swap columns use the followng code  
  #array[:,[0,4]]=array[:,[4,0]]
  #To shift each column in an array use np.roll() in numpy
  array=np.roll(array, 1, axis=1)
  #print(array, '\n')
  image = cv2.imread(testlist[i])
  height,width= image.shape[0],image.shape[1]
  #print(height,width)
  #print('\n')
  #print(len(array))
  #print(array[:][:])
  for j in range(int(countofdetectionsinparticularimage)):
    for k in range(1,5):
      #print(k)
      if(k== 2):
        array[j][k]=int(array[j][k])/height
        #if array[j][k]>1:
         # print('error2')
         # print(array[j][k],height,width)
      if(k == 4):
        array[j][k]=int(array[j][k])/height
        #if array[j][k]>1:
          #print('error4')
          #print(array[j][k],height,width)
      if(k== 3):
        array[j][k]=int(array[j][k])/width
        #if array[j][k]>1:
          #print('error3')
          #print(array[j][k],height,width)
      elif(k==1 ):
        array[j][k]=int(array[j][k])/width
        #if array[j][k]>1:
          #print('error1')
          #print(array[j][k],height,width)
  #print(array, '\n')
  with open('{}'.format(testlistnamestextfiles[i]), 'w') as f:
    for x in range(int(countofdetectionsinparticularimage)):

      for y in range(5):
        if y==0 :
          f.write(str(0) + ' ')
        else :
          f.write(str(float(array[x][y])) + ' ')
      f.write('\n')

#Zipping the entire data folder and dowloading to avoid multiple data preperation. Please follow the steps below.
!zip -r /content/obj.zip /content/ShelfImages/

# Commented out IPython magic to ensure Python compatibility.
#Mounting Google drive to colab
# %cd 
# %cd ..
# %cd content/
from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd 
# %cd ..
!ln -s /content/gdrive/'My Drive/' /mydrive

# Commented out IPython magic to ensure Python compatibility.
#changing directory to content . 
# %cd 
# %cd ..
# %cd content
# clone darknet repo
!git clone https://github.com/AlexeyAB/darknet

# use this code to check the cuda version installed in the GPU ( not much necessary)
!nvcc --version

# Commented out IPython magic to ensure Python compatibility.
#Making Darknet as the working directory.
# %cd darknet

# since we are GPU powered we have to change some lines of the make file to enable GPU usage on darknet 
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile

# this makes the darknet . in windows it creates an exe software and in linux it makes 
!make

#list files in yolov3 folder 
!ls /mydrive/yolov3/yolov3

# Commented out IPython magic to ensure Python compatibility.
#Run this cell if your data is in obj folder in yolov3 folder in your drive. 
# %cd 
# %cd ..
# %cd content/gdrive/'My Drive'/yolov3/yolov3
!zip -r /content/obj.zip ./obj

# Commented out IPython magic to ensure Python compatibility.
# unzip the zip file and its contents Into darknet/data folder.  the images and text files  should now be in /darknet/data/obj
# %cd 
# %cd .. 
# %cd content
!unzip /content/obj.zip -d darknet/data

# Commented out IPython magic to ensure Python compatibility.
#Copy config file Which is 

# %cd 
# %cd .. 
# %cd content
!cp /mydrive/yolov3/yolov3/yolov3_custom.cfg darknet/cfg/

# Commented out IPython magic to ensure Python compatibility.
# upload the obj.names and obj.data files and pre trained weights to cloud VM from Google Drive
# %cd 
# %cd .. 
# %cd content
!cp /mydrive/yolov3/yolov3/obj.names darknet/data
!cp /mydrive/yolov3/yolov3/obj.data  darknet/data
!cp /content/gdrive/MyDrive/yolov3/yolov3/darknet53.conv.74  darknet/data #%cd darknet  #!wget https://pjreddie.com/media/files/darknet53.conv.74 would do the same if you dont want to download.

"""Training for the first time"""

# Commented out IPython magic to ensure Python compatibility.
#This snippet of code starts training by making the 
# %cd
# %cd ..
# %cd content/darknet
!./darknet detector train data/obj.data cfg/yolov3_custom.cfg darknet53.conv.74 -dont_show

"""Training after 100 iterations, if it is stopped due to connectivity issues or you find your model inaccurate and you want to train more"""

# Commented out IPython magic to ensure Python compatibility.
#This snipped obtains the last saved back up files and resumes training from there
# %cd 
# %cd ..
# %cd content
!cp /content/gdrive/'My Drive'/yolov3/yolov3/yolov3_custom_last.weights /darknet
# %cd darknet/
!./darknet detector train data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights -dont_show

!./darknet detector valid data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights

# Commented out IPython magic to ensure Python compatibility.
# %cd 
# %cd ..
# %cd content
!cp /content/gdrive/MyDrive/yolov3/yolov3/backup/yolov3_custom_last.weights /darknet

!./darknet detector recall data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights

!./darknet detector map data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights

!./darknet detector precision data/obj.data cfg/yolov3_custom.cfg yolov3_custom_last.weights

dictionary = {
    'mAP' : 0.8841,
    'precision' : 0.95,
    'recall' : 0.85
}
import json 
with open('metrics.json', 'w') as fp:
    json.dump(dictionary, fp)

